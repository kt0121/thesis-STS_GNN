% 本原稿用の条件マクロ
%章ごとにコンパイルできるようにするための設定．
%このマクロが定義されていない場合，チャプター内は個別のTEXソースとして扱われる．
\expandafter\ifx\csname MasterFile\endcsname\relax
\documentclass[a4j,twoside,12pt, dvipdfmx]{thesis} % 修論・卒論など (ページが右端にでる) 
\usepackage{amsmath, amssymb}
\usepackage{mysettings}
\usepackage{graphicx}
\usepackage{color}
\usepackage{comment}

\begin{document}

\addtocounter{chapter}{+2}

\setlength{\baselineskip}{1.95zw}
\setlength{\textheight}{30\baselineskip}
\mainmatter

\fi
% これより上は削除しちゃダメ
% 本原稿用の条件マクロここまで
%
%\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\renewcommand\thefootnote{\arabic{footnote})}
\def\vector#1{\mbox{\boldmath $#1$}}

\chapter{提案手法}\label{meth}
% ここに本文
本章では,提案手法について説明する.本研究は大きく分けて以下の 4 つに分類される.
\begin{enumerate}
  \item 文からのグラフ作成
  \item ノードの特徴量畳込み
  \item グラフを表現する埋め込み生成
  \item グラフ間の類似度の評価
\end{enumerate}
それぞれの方法について 2 種類の手法を採用し, 計 16 種類の手法で比較を行った. \par
モデルの概要を図\ref{fig:ModelFlow}に示す.
\begin{figure}
  \centering
  \includegraphics[width=\linewidth]
  {img/ModelFlow.jpg}
  \caption{モデルの概要}
  \label{fig:ModelFlow}
\end{figure}

\ref{meth:createGraph}節では文からのグラフ作成,\ref{meth:convNode}節ではノード畳込み \ref{meth:createEmbedding}節ではグラフを表現する埋め込み生成, \ref{meth:calculateSimilarity}節ではグラフ間の類似度計算について述べる.

\section{文からのグラフ作成}\label{meth:createGraph}
本節では,文からのグラフ生成手法について説明する.\
グラフの生成について,以下の２つを行う.
\begin{enumerate}
  \item ノード生成
  \item エッジ生成
\end{enumerate}
また, 本研究では以下の２通りのエッジ生成方法を元に, 2 種類のグラフを生成し実験した.
\begin{enumerate}
  \item 依存関係に基づくエッジ生成
  \item 依存関係と隣接関係に基づくエッジ生成
\end{enumerate}

\subsection{ノード生成}\label{meth:createNode}
文からのグラフの生成において,各ノードはそれぞれの単語とし,その単語のレンマの埋め込みを取得し,ノードの特徴量とした.

\subsection{エッジ生成}\label{meth:createEdge}
構文情報には単語間の依存情報や隣接関係などが存在する. そこで本研究では, 依存関係に基づくエッジの生成方法と, それに加えて隣接関係も追加したエッジの生成方法の 2 つを採用した.
隣接関係のみに基づくエッジの生成を行わなかった理由としては, 隣接関係のみだとグラフ構造が鎖状になってしまうためである.
\subsubsection*{依存関係に基づくエッジ生成}
各エッジの生成には Universal Dependencies に基づく構文解析を行い,単語間に依存関係があれば双方向にエッジを作成し,無向グラフを生成した.

\subsubsection*{依存関係と隣接関係に基づくエッジ生成}
依存関係に基づくエッジ生成に加えて, 単語間に隣接関係があれば双方向エッジを作成し,無向グラフを生成した.

\section{ノードの特徴量畳込み}\label{meth:convNode}
本節では, ノードの特徴量畳込み手法について説明する.
ノードの特徴量畳み込みでは 2 通りの方法を採用した.
\subsection{Graph Convolutional Network (GCN)}
この方法では,ノードの畳み込みに Kipf ら\cite{kipf2017semi}と同様の Graph Convolutional Network (GCN) を用いた.
この方法は SimGNN\cite{bai2019simgnn}でも用いられている.
GCN の第$l$層における出力は式\ref{eq:methGCN}で表される.
\begin{equation}
  \label{eq:methGCN}
  H^{(l)}=f(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l-1)}W_{1}^{(l-1)})
\end{equation}
ここで,$\tilde{A} = A + I_{N}$はノード自身へのエッジを追加した無向グラフの隣接行列であり,$I_N$は単位行列である.
$\tilde{D}_{ii} = \sum_{j} \tilde{A}_{ij}$であり,$W_{1}^{(l)}$は層に応じた学習可能な重み行列,$f(\cdot)$は$ReLU(\cdot) = \max (0, \cdot)$のような活性化関数である.
また,$H^{(0)}=X$となる.

\subsubsection{GraphSAGE}
この方法では, ノードの畳み込みに GraphSAGE\cite{hamilton2017inductive} (SAGE) を用いた.
本手法を採用した背景は, 近傍ノードをサンプリングして学習する GraphSAGE を用いることで, グラフサイズの影響を減らして効果的に特徴量の畳み込みができるだろうと言う直感に基づいている.
aggregator には, MeanAggregator を用いる.
Mean aggregator を用いた場合, ノード$v$に対する GraphSAGE の第$l$層の出力は式\ref{eq:methGraphSAGE}で表される.
\begin{equation}
  \label{eq:methGraphSAGE}
  h_{v}^{l} \leftarrow \sigma(\mathbf{W_{2}} \cdot \mathrm{MEAN} (\{ \mathbf{h}_{v}^{l-1}\} \cup \{ \mathbf{h}_{u}^{l-1} , \forall u \in \mathcal{N}(v) \}))
\end{equation}
ここで, $\mathbf{h}_{v}^{l}$は第$l$層でのノード$v$の埋め込みであり, $\mathbf{W_{2}}$は学習可能な重み行列, $\mathcal{N}(v)$はノード$v$の近傍ノード郡である.

\section{グラフを表現する埋め込み生成}\label{meth:createEmbedding}
本節では,グラフを表現する埋め込み生成手法について説明する.
グラフを表現する埋め込み生成では 2 通りの方法を採用した.
これらの方法では, 前節の方法で得られたノードレベルの埋め込みを元にグラフを表現する埋め込みを生成する.

\subsection{アテンションモジュール}
この方法は SimGNN で用いられているアテンションモジュール (Att) と同様のものである.
アテンションモジュールから出力される, グラフを表現する埋め込み$h$は以下の式で表される.
\begin{equation}
  h = \sum_{n=1}^{N}\sigma(u_{n}^\mathsf{T}c)u_{n}= \sum_{n=1}^{N}\sigma(u_{n}^\mathsf{T} \tanh (\frac{1}{N}W_{2}\sum_{m=1}^{N}u_{m}))u_{n}
\end{equation}
ここで, $u_{n}$ はノード$n$の埋め込み, $\sigma$ はシグモイド関数, $N$はノード数, $W_{2}$は学習可能な重み行列である.

\subsection{SAGPool}
この方法では, グラフを表現する埋め込み生成に Self-Attention Graph Pooling (SAGPool) \cite{lee2019self} を用いた.
本手法を採用した背景は, 畳み込みを行った後に最も周辺ノードの情報を集めることができたノードはグラフ全体を表しているのではないかという直感に基づいている.
SAGPool では, 各ノードの重要度を式\ref{eq:methAtt} で算出し, 重要度が最も高いノードの表現からグラフを表現する埋め込みを取得する.
\begin{equation}
  \label{eq:methAtt}
  Z = \sigma (\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}X\Theta_{att})
\end{equation}
ここで, $\tilde{A} = A + I_{N}$はノード自身へのエッジを追加した無向グラフの隣接行列であり,$I_N$は単位行列である.
$\tilde{D}_{ii} = \sum_{j} \tilde{A}_{ij}$であり$\Theta_{att}$は SAGPool 層のパラメータである.

\section{グラフ間の類似度計算}\label{meth:calculateSimilarity}
本節では, グラフ間の類似度計算手法について説明する.
グラフ間の類似度計算では 2 通りの方法を採用した.
これらの方法では, 前節の方法で得られたグラフを表現する埋め込みから類似度を計算する.

\subsection{ニューラルテンソルネットワーク}
この方法は SimGNN で用いられている ニューラルテンソルネットワーク (NTN) と同様のものである.
2 つのグラフの埋め込み$h_{i}$, $h_{j}$を ニューラルテンソルネットワーク に与えた出力は式\ref{eq:NTN}である.
\begin{equation} \label{eq:NTN} g(h_{i}, h_{j})=f(h_{i}^\mathsf{T}W_{3}^{[1:K]}h_{j} + V \begin{bmatrix} h_{i}\\h_{j} \end{bmatrix} + b)\end{equation}
を用いる.
ここで,$W_{3}^{[1:K]} \in R^{D \times D \times K}$は重み行列,$\begin{bmatrix} $ $ \end{bmatrix}$は結合操作,$V \in \mathbb{R}^{K\times2D}$は重みベクトル.
$b \in \mathbb{R}^{K}$はバイアスベクトル, $f(\cdot)$は$ReLU(\cdot) = \max (0, \cdot)$のような活性化関数である.得られた出力を 2 層の全結合層に与えることで, 最終的な類似度を得る.

\subsection{コサイン類似度}
この方法はコサイン類似度 (cos) を用いてグラフ間の類似度計算を行うものである.
本手法を採用した理由は, ベクトル間の類似度を求めるのに一般的に用いられているコサイン類似度を利用することで, ニューラルテンソルネットワークの有効性を検証するためである.
2 つのグラフの埋め込み$h_{i}$, $h_{j}$のコサイン類似度は,式\ref{eq:cos}で表される.
\begin{equation}
  \label{eq:cos}
  \cos(h_{i}, h_{j}) = \dfrac{h_{i} \cdot h_{j}}{|h_{i} | | h_{j}|}
\end{equation}

% 本原稿用の条件マクロ
% これ以降は削除しちゃダメ
\expandafter\ifx\csname MasterFile\endcsname\relax
\def\MasterFile{本原稿です}

% 参考文献
%\include{reference}

\bibliographystyle{junsrt}
\bibliography{thesisB}

\end{document}
\fi
% 本原稿用の条件マクロここまで
